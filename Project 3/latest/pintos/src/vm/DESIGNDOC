       	       	    +---------------------------+
		    |		CS 140		|
		    | PROJECT 3: VIRTUAL MEMORY	|
		    |	   DESIGN DOCUMENT	|
		    +---------------------------+

---- GROUP ----

>> Fill in the names and email addresses of your group members.

Akshay Sawant <asawant@zimbra.ccs.neu.edu>
Nikkhil Muthye <nikkhil@zimbra.ccs.neu.edu>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

--> We had designed the system in a way which could handle shared memory.
    But due to the time constraint, we could not implement shared memory.
    So the data structures were designed with view of implementing the same.
    It might contain some fields which were useful for sharing.

			PAGE TABLE MANAGEMENT
			=====================

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

--> 
struct frame
  {
    uint32_t *phy_addr;     // To hold the physical address for a frame 
    struct thread *process; // The thread currently holding the frame
    uint32_t *vaddr;        // The virtual address of the process which 
                            // is mapped to this frame's physical page.
    bool write;             // Flag to identify whether the frame is writable 
                            // or not.
    bool free;              // Flag to identify whether the frame is free 
                            // or not.
    struct list_elem elem;  // list_elem to identify the frame in the LRU 
                            // queue.
  };

static struct list lru_queue; 
--> The LRU queue list to hold the frames in order in which they are accessed.

enum swap_status
  {
    IN_MEMORY, // The virtual page is in the main memory.
    IN_SWAP,   // The virtual page is in the swap disk.
    IN_FILE    // The virtual page is on the file.
  };

enum page_type
  {
    MMAP,  // The page is memory mapped.
    CODE,  // The page is from the code segment.
    DATA   // The page is from the data segment (stack and data).
  };


/* Structure for an entry of Supplement Page table */
struct sup_page
  {
    uint32_t *vaddr;    	// The virtual address for which the page is mapped.
    uint32_t *paddr;    	// The physical address if the page is in memory.
    enum page_type ptype; 	// The type of page which can be either mmap, code
                          	// or data.
    enum swap_status status; 	// The location of the page. It can be either in
                             	// in the file, memory or on the swap disk.
    struct file *file;  	// The file from which we load the various segments
				// or read data from.
    off_t ofs;        		// The offset within the file to read the code/data.
    uint32_t read_bytes; 	// The total number of bytes we have to read from
                         	// the file at given offset.
    block_sector_t swaddr; 	// The sector number of the page in the swap disk.
    struct hash_elem elem; 	// Elem field for list.
  };

/* Structure to store details of Code and Stack segment.
 * This variable will be used to identify overlapping of pages. */
struct seg_details
  {
    void *start_addr;                   /* Segment start address. */
    void *end_addr;                     /* Segment end address. */
    int pages;                          /* Total number of pages assigned till now. */
  };

struct hash sup_page_table;
--> The Supplimental Page Table which will be used to store the supplimental pages
    information


---- ALGORITHMS ----

>> A2: In a few paragraphs, describe your code for locating the frame,
>> if any, that contains the data of a given page.
--> In our design, we have implemented the frame table using a list
    and supplimental page table using a hash table. 
    1. When we have to locate a frame that contains the data of a given 
       frame, we first lookup the page_table. If the page_table contains
       mapping between virtual and physical address, then we use it.
       Otherwise page_fault occurs. In this scenario, interrupt occurs.
       In page_fault handler function, we lookup supplimental page table
       and locate the corresponding supplimental page table entry for
       the given virtual address. 
    2. When we get the supplimental page table entry, we check the 
       swap_status for the page.
    3. If the page is in swap disk, then we get the sector number
       at which the data is stored on the swap disk from supplemental page
       table. We have to allocate a physical frame to swap in the required
       page from swap disk. If no frames are free, we evict one of the frames 
       in physical memory. To handle eviction, we have used LRU + Clock
       alogorithm.
    4. Once we have the physical page, we then have to read from the swap disk
       into the memory. As we already have the sector number, we then copy the 
       block_read () function to get the data into a given physical page.
    5. In case the page_faulted page is in file, then we use file pointer and
       offset from supplemental page table to read data from file.


>> A3: How does your code coordinate accessed and dirty bits between
>> kernel and user virtual addresses that alias a single frame, or
>> alternatively how do you avoid the issue?
--> Our code co-ordinates the accessed and dirty bytes between the kernel and
    user virtual addresses that alias the same frame by checking and 
    updating them.
    For eg: During functions such as memory unmap or swap out, we first check 
            whether the dirty bit is set or not. If the dirty bit is set, it 
	    means the page was previously written to and hence it has been
	    marked "dirty". So if any user or kernel virtual address points to
	    a frame which was previously marked as dirty, the frame is treated
	    as dirty. In case, the dirty frame is selected for eviction, then,
	    for data page, frame is swapped out and written to into the swap
	    disk. And for memory mapped page, we write page back into the file.
    We use access bits also in a similar manner. When frame table is full and
    a new page is requested, we use accessed bits to determine the frame to be
    evicted. The accessed bit indicates that the frame was previously at some 
    point of time being accessed. Frame whose access bit is not set is selected
    for eviction.

---- SYNCHRONIZATION ----

>> A4: When two user processes both need a new frame at the same time,
>> how are races avoided?
--> When two frames want a new frame at the same time, they would first have
    acquire a lock, frame_lock and only then can they get a new frame.
    In this problem, we can have three scenarios ->
    1. Both process P and process Q gets the new frame from the function
       palloc_get_page (). Now that they have got a new physical page 
       allocated, we have to add their entires into the frame table. We do
       this sequantially which means that only the thread holding the lock
       to the frame table can enter it's frame information.
    2. Both the processes P and Q do not get a physical page, in which
       situation, we will have to evict a frame. Inorder to perform an
       eviction, we will have to hold the frame lock which would guarrantee
       sequential execution.
    3. Only one of the process gets a page from palloc_get_page (), while the
       other doesn't. In this case, the first thread would add it's information
       into the frame table whereas the second thread would have to perform an
       eviction. For both these cases, the thread woud require the frame_lock.

---- RATIONALE ----

>> A5: Why did you choose the data structure(s) that you did for
>> representing virtual-to-physical mappings?
--> The major concern in this project was the speed if querying the information
    in the supplimental page table. We decided to use hash table to implement 
    the supplimental page table as it would give O(1) complexity for lookup. 
    Inorder to perform LRU algorthm, we have implemented the frame table as a 
    as a list.
    The frame table is a global list. We use this table for eviction to determine
    next frame to be evicted. We implemented frame table as a list as we wanted
    to implement the Clock Algorithm.
    We have implemneted the management of swap slots using the bitmap structure
    The management of the bitmap is very straight forward. We find the first 
    available slot in the bitmap and map the swapped out page to this swap
    slot of swap disk.
    


		       PAGING TO AND FROM DISK
		       =======================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

In struct thread ==>

struct seg_details stack_seg;
--> The seg_details structure which will hold the information on the stack segment.

struct seg_details code_seg;
--> The seg_details structure which will hold the information on the code segment.

struct file *exec_file;
--> The file which is currently executing. We use this file as in load segment, we 
    close the file in the end.

uint32_t fault_esp;
--> User esp. We store esp before we enter the kernal mode. This is helpful
    in page_fault handling to determine the stack growth.
 
---- ALGORITHMS ----

>> B2: When a frame is required but none is free, some frame must be
>> evicted.  Describe your code for choosing a frame to evict.
--> When a process needs a frame, we first call a function get_available_frame()
    which would give us a frame from the frame table if available. If there is a frame 
    which was previously freed by some process, that frame would be allocated.
    
    If there is no free frame available, we then try to allocate a new page by
    calling palloc_get_page (). If page allocation fails, this means there is no
    free frame available, hence the frame table is full.

    In such situation, we need to evict one frame from the frame table.
    For evicting a suitable frame from the frame table, we have used a 
    combination of LRU algorithm and clock algorithm. To implement LRU
    algorithm, we have used a list structure for all the frames. In case of
    a page fault, if a frame is allocated, then we push back the newly allocated 
    frame in frame table list. This ensures that the least recently allocated
    frame is at the start of the frame table list. We traverse the list in
    circular order to implement Clock Algorithm. The frame whose access bit is
    not set, will be used for eviction.


>> B3: When a process P obtains a frame that was previously used by a
>> process Q, how do you adjust the page table (and any other data
>> structures) to reflect the frame Q no longer has?
--> In our design, the frame table is used to keep track of all the 
    physical pages and it's physical to virutal page mapping with the related
    thread. When a process P obtains a frame which was previously used by
    process Q, the frame structure which was previously owned by process Q
    would be updated in the palloc_get_frame (). After we have swapped out the page 
    from the physical memory owned by process Q, we set owner of the frame to NULL.
    Also, to notify process Q that the frame in context is no longer associated
    with process Q, we update the corresponding entry in supplement page table of
    process Q with status as IN_FILE / IN_SWAP depending where the page is swapped
    out.
    Hence, when process P acquires the frame released by process Q, it will
    mark the owner of the frame to process P and map virtual address in
    frame table to the virtual address of the process P.


>> B4: Explain your heuristic for deciding whether a page fault for an
>> invalid virtual address should cause the stack to be extended into
>> the page that faulted.
--> In order to decide whether the page fault has occurred due to stack
    growth, we have provided two information: the maximum size that the 
    stack can grow and the stack pointer of the user process before the page
    fault has occurred.

    As we depend on the page faults for an invalid address, we need to save
    the value of the esp before the exception has occurred. As the PUSHA 
    instruction could cause an access to be 32 bytes below the
    stack pointer, any user memory access between PHYS_BASE and esp - 32 is
    valid. Also, we have to make sure that the size of the stack does not 
    go beyond 8MB. If it tries to grow beyond that, we would simply exit.


---- SYNCHRONIZATION ----

>> B5: Explain the basics of your VM synchronization design.  In
>> particular, explain how it prevents deadlock.  (Refer to the
>> textbook for an explanation of the necessary conditions for
>> deadlock.)
--> In our design, we have pinned some important pages which should
    not get evicted. If evicted, they might cause the system to go into
    a deadlock situaiton.
    Hence, we pin the pages of the userprog which are currently accessed in
    the syscall handler. The kernel pins the page being accessed so that 
    it wont get evicted. We also pin the stack pages.
    When a page fault occurs and a frame needs to be evicted. We will not
    consider pinned frames for eviction.
    The pinned status is maintained the the supplimental page table entry.
    Once the syscall for the user program ends, we set the pinned status
    for that page as false.
    This would help in solving the deadlock situation as the currently running
    page won't be swapped out.


>> B6: A page fault in process P can cause another process Q's frame
>> to be evicted.  How do you ensure that Q cannot access or modify
>> the page during the eviction process?  How do you avoid a race
>> between P evicting Q's frame and Q faulting the page back in?
-->  In above mentioned scenario, when process P requests for a frame,
   which leads to eviction of process Q's frame, then kernel free the frame
   by marking frame as available and clearing the process and virtual
   address inside frame structure. Also, kernel notifies process Q
   by clearing it's entry from page table. Kernel then moves the data
   from frame to file or swap disk based on type of page. It also
   notifies the process Q about frame being evicted by updating
   process Q's supplemental page table entry.
   The race condition between P evicting Q's frame and Q faulting the
   page back in is avoided as follows - 
   Process P evicts process Q's frame. Before the control is returned
   from page_fault for process P, if process Q's faults on the same
   evicted page, then it would cause another page fault. This will
   require process Q to allocate another frame. And the data will
   be swapped in for process Q.


>> B7: Suppose a page fault in process P causes a page to be read from
>> the file system or swap.  How do you ensure that a second process Q
>> cannot interfere by e.g. attempting to evict the frame while it is
>> still being read in?
--> While process P is trying to read a page from the file or from the swap
    disk, we pin it's supplimental page table entry i.e. we prohibit any other
    thread to evict the frame which process P is reading into.
    So, when process Q comes into execution, it may again try to evict a
    frame. But as we have pinned the frame which process P is reading 
    into, that frame will not ever get evicted.

    In a situation where process Q has selected a frame to evict before 
    process P pinned it, process Q will evict the frame. When process P
    comes into execution, it will page fault. 


>> B8: Explain how you handle access to paged-out pages that occur
>> during system calls.  Do you use page faults to bring in pages (as
>> in user programs), or do you have a mechanism for "locking" frames
>> into physical memory, or do you use some other design?  How do you
>> gracefully handle attempted accesses to invalid virtual addresses?
--> In our design, we load pages lazily that have not yet been loaded and
    pinned so that the page will not be swapped out while it is being used.
    Yet, if aan access to paged-out pages occur during the system call, then
    we simply kill the user process. This is done by calling user_exit()
    function with status as -1.


---- RATIONALE ----

>> B9: A single lock for the whole VM system would make
>> synchronization easy, but limit parallelism.  On the other hand,
>> using many locks complicates synchronization and raises the
>> possibility for deadlock but allows for high parallelism.  Explain
>> where your design falls along this continuum and why you chose to
>> design it this way.
--> We have used different locks to implement parallelism. But this could
   lead to deadlock situations. Hence, we have distributed use of different 
   locks to each different functionality and reduced the possibility of
   deadlock.
   Also, we have used system of pinning frames, so as to avoid swapping
   out pages which are currently accessed inside page fault handler.
   This reduces parallelism but improves synchronization without using
   additional locks.


			 MEMORY MAPPED FILES
			 ===================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.
-->

struct mmap_file
  {
    mmapid_t mmid;   	// The ID for the mapped memory file.
    struct file *file; 	// The file which is memory mapped.
    void *start_addr; 	// The virtual start address for the MMAP
    uint32_t pages;  	// The total number of pages allocated below the
                     	// start address.
    struct list_elem elem; // List element to maintain list.
  };

struct list mmap_files;
// the list of memory mapped files for the given file.

---- ALGORITHMS ----

>> C2: Describe how memory mapped files integrate into your virtual
>> memory subsystem.  Explain how the page fault and eviction
>> processes differ between swap pages and other pages.
--> All the memory mapped files are loaded lazily similar to the 
    other segments in the executable files.
    This mean, when user programs calls mmap system call, kernel will
    simply create corresponding entries in supplement page table
    and state that the data is in file.
    When a page fault occurs, the memory mapped files would be read 
    from the file just like the executables. They would then be
    allocated frame and the virtual to physical mapping for the memory
    mapped page is done.
    The main difference is that the memory mapped pages when evicted,
    are written back to respective file instead of swap disk.
    Before memory mapped page is evicted, kernel does some basic checks.
    If the page is marked dirty, then it is written back to file.
    Similarly in case of munmap and when thread exits, kernel would
    iterate through the list of mmap files of current thread and 
    write back the dirty pages back into the mmap file. Then we close 
    the memory mapped files.


>> C3: Explain how you determine whether a new file mapping overlaps
>> any existing segment.
--> Supplemental page table stores all the virtual pages required by a process.
    Hence while creating entry for memory mapped file, we look up into
    supplemental page table. If no entry exists for current virtual address
    then we create entry. If an entry exists for current virtual address,
    then the page overlaps. Hence, we unmap all previous supplement page
    table entries for this mmap system call.


---- RATIONALE ----

>> C4: Mappings created with "mmap" have similar semantics to those of
>> data demand-paged from executables, except that "mmap" mappings are
>> written back to their original files, not to swap.  This implies
>> that much of their implementation can be shared.  Explain why your
>> implementation either does or does not share much of the code for
>> the two situations.
--> The mmap files and the executable files both are loaded lazily into
    the memory. In both scenarios, we first make entries in supplement
    page table and then load pages lazily. Hence, our design shares the
    code which creates an entry in supplement page table. But this function
    is called from different functions in case of executables and mmap-ed
    files. This is so, because in mmap-ed files, we detect if mapping
    file into memory overlaps any other used virtual page. In this scenario,
    we remove all previous entries for this file from supplement page
    table and return error status. Such check is not performed for
    executables.

    


			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

>> Any other comments?
